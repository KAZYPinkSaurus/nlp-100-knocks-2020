{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1章: 準備運動"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. 文字列の逆順\n",
    "文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"stressed\"[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 「パタトクカシーー」\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パトカー'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"パタトクカシーー\"[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パタトクカシーー'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1 = \"パトカー\"\n",
    "word2 = \"タクシー\"\n",
    "\"\".join([_word1 + _word2 for _word1, _word2 in zip(word1, word2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 円周率\n",
    "“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 4, 1, 6, 9, 2, 7, 5, 3, 5, 8, 9, 7, 10]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "\n",
    "[len(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 元素記号\n",
    "“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭の2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'H': 1,\n",
       " 'He': 2,\n",
       " 'Li': 3,\n",
       " 'Be': 4,\n",
       " 'B': 5,\n",
       " 'C': 6,\n",
       " 'N': 7,\n",
       " 'O': 8,\n",
       " 'F': 9,\n",
       " 'Ne': 10,\n",
       " 'Na': 11,\n",
       " 'Mi': 12,\n",
       " 'Al': 13,\n",
       " 'Si': 14,\n",
       " 'P': 15,\n",
       " 'S': 16,\n",
       " 'Cl': 17,\n",
       " 'Ar': 18,\n",
       " 'K': 19,\n",
       " 'Ca': 20}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "words = text.split()\n",
    "b = [1, 5, 6, 7, 8, 9, 15, 16, 19]\n",
    "\n",
    "dic = {}\n",
    "for idx, word in enumerate(words):\n",
    "    c = 2\n",
    "    if idx + 1 in b:\n",
    "        c = 1\n",
    "    dic[word[:c]] = idx + 1\n",
    "\n",
    "dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. n-gram\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "text = \"I am an NLPer\"\n",
    "\n",
    "\n",
    "def n_gram(text, n=2, mode=\"tango\"):\n",
    "    if mode == \"tango\":\n",
    "        text = text.split()\n",
    "    if len(text) < n:\n",
    "        return []\n",
    "    return [text[idx : idx + n] for idx in range(len(text) - n + 1)]\n",
    "\n",
    "\n",
    "print(n_gram(text, mode=\"tango\"))\n",
    "print(n_gram(text, mode=\"moji\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 集合\n",
    "“paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和集合:{'ag', 'se', 'gr', 'ph', 'ad', 'ar', 'is', 'pa', 'ap', 'di', 'ra'}\n",
      "積集合:{'pa', 'ap', 'ar', 'ra'}\n",
      "差集合:{'ad', 'se', 'di', 'is'}\n",
      "差集合:{'ph', 'ag', 'gr'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"paraparaparadise\"\n",
    "text2 = \"paragraph\"\n",
    "\n",
    "text1 = n_gram(text1, mode=\"moji\")\n",
    "text2 = n_gram(text2, mode=\"moji\")\n",
    "print(f\"和集合:{set(text1) | set(text2)}\")\n",
    "print(f\"積集合:{set(text1) & set(text2)}\")\n",
    "print(f\"差集合:{set(text1) - set(text2)}\")\n",
    "print(f\"差集合:{set(text2) - set(text1)}\")\n",
    "\n",
    "\"se\" in set(text1) & set(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. テンプレートによる文生成\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12時の気温は22.4'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func1 = lambda x, y, z: f\"{x}時の{y}は{z}\"\n",
    "\n",
    "x = 12\n",
    "y = \"気温\"\n",
    "z = 22.4\n",
    "\n",
    "func1(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. 暗号文\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "\n",
    "英小文字ならば(219 - 文字コード)の文字に置換\n",
    "その他の文字はそのまま出力\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I zn KAZY uiln Jzkzm\n",
      "I am KAZY from Japan\n"
     ]
    }
   ],
   "source": [
    "def cipher(text, mode=\"encode\"):\n",
    "    if mode == \"decode\":\n",
    "        return \"\".join([chr(219 - ord(txt)) if txt.islower() else txt for txt in text])\n",
    "    return \"\".join([chr(219 - ord(txt)) if txt.islower() else txt for txt in text])\n",
    "\n",
    "\n",
    "a = \"I am KAZY from Japan\"\n",
    "a = cipher(a, mode=\"encode\")\n",
    "print(a)\n",
    "a = cipher(a, mode=\"decode\")\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I c’duolnt bielvee that I colud atuaclly uratsdnned what I was redniag : the pnmoeneahl poewr of the hamun mind .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "import random\n",
    "\n",
    "\n",
    "def func2(text):\n",
    "    shuffle = (\n",
    "        lambda x: f\"{x[0]}{''.join(random.sample([_x for _x in x[1:-1]],len(x[1:-1])))}{x[-1]}\"\n",
    "    )\n",
    "    return \" \".join([shuffle(txt) if len(txt) > 4 else txt for txt in text.split()])\n",
    "\n",
    "\n",
    "print(text)\n",
    "func2(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('nlp-100-knocks-2020-UTXiV_Xd-py3.8': venv)",
   "language": "python",
   "name": "python38264bitnlp100knocks2020utxivxdpy38venv6f1bdc414e1c42079574c87f4d492959"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第8章: ニューラルネット\n",
    "第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 70. 単語ベクトルの和による特徴量\n",
    "問題50で構築した学習データ，検証データ，評価データを行列・ベクトルに変換したい．例えば，学習データについて，すべての事例$x_i$の特徴ベクトル$x_i$を並べた行列$X$と，正解ラベルを並べた行列（ベクトル）$Y$を作成したい．\n",
    "$$$\n",
    "X = \\begin{pmatrix} \n",
    "  \\boldsymbol{x}_1 \\\\ \n",
    "  \\boldsymbol{x}_2 \\\\ \n",
    "  \\dots \\\\ \n",
    "  \\boldsymbol{x}_n \\\\ \n",
    "\\end{pmatrix} \\in \\mathbb{R}^{n \\times d},\n",
    "Y = \\begin{pmatrix} \n",
    "  y_1 \\\\ \n",
    "  y_2 \\\\ \n",
    "  \\dots \\\\ \n",
    "  y_n \\\\ \n",
    "\\end{pmatrix} \\in \\mathbb{N}^{n}\n",
    "$$$\n",
    "ここで，$n$は学習データの事例数であり，$x_i \\in R^d$とyi∈ℕはそれぞれ，i∈{1,…,n}番目の事例の特徴量ベクトルと正解ラベルを表す． なお，今回は「ビジネス」「科学技術」「エンターテイメント」「健康」の4カテゴリ分類である．ℕ<4で4未満の自然数（0を含む）を表すことにすれば，任意の事例の正解ラベルyiはyi∈ℕ<4で表現できる． 以降では，ラベルの種類数をLで表す（今回の分類タスクではL=4である）．\n",
    "\n",
    "i番目の事例の特徴ベクトルxiは，次式で求める．\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x}_i = \\frac{1}{T_i} \\sum_{t=1}^{T_i} \\mathrm{emb}(w_{i,t})\n",
    "$$\n",
    "ここで，i番目の事例はTi個の（記事見出しの）単語列(wi,1,wi,2,…,wi,Ti)から構成され，emb(w)∈ℝdは単語wに対応する単語ベクトル（次元数はd）である．すなわち，i番目の事例の記事見出しを，その見出しに含まれる単語のベクトルの平均で表現したものがxiである．今回は単語ベクトルとして，問題60でダウンロードしたものを用いればよい．300次元の単語ベクトルを用いたので，d=300である．\n",
    "\n",
    "i番目の事例のラベルyiは，次のように定義する．\n",
    "$$\n",
    "% <![CDATA[\n",
    "y_i = \\begin{cases}\n",
    "0 & (\\mbox{記事}x_i\\mbox{が「ビジネス」カテゴリの場合}) \\\\\n",
    "1 & (\\mbox{記事}x_i\\mbox{が「科学技術」カテゴリの場合}) \\\\\n",
    "2 & (\\mbox{記事}x_i\\mbox{が「エンターテイメント」カテゴリの場合}) \\\\\n",
    "3 & (\\mbox{記事}x_i\\mbox{が「健康」カテゴリの場合}) \\\\\n",
    "\\end{cases} %]]>\n",
    "$$\n",
    "\n",
    "なお，カテゴリ名とラベルの番号が一対一で対応付いていれば，上式の通りの対応付けでなくてもよい．\n",
    "\n",
    "以上の仕様に基づき，以下の行列・ベクトルを作成し，ファイルに保存せよ．\n",
    "\n",
    "- 学習データの特徴量行列: Xtrain∈ℝNt×d\n",
    "- 学習データのラベルベクトル: Ytrain∈ℕNt\n",
    "- 検証データの特徴量行列: Xvalid∈ℝNv×d\n",
    "- 検証データのラベルベクトル: Yvalid∈ℕNv\n",
    "- 評価データの特徴量行列: Xtest∈ℝNe×d\n",
    "- 評価データのラベルベクトル: Ytest∈ℕNe\n",
    "\n",
    "なお，Nt,Nv,Neはそれぞれ，学習データの事例数，検証データの事例数，評価データの事例数である．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "\n",
    "# word2becモデル読み込み\n",
    "model = KeyedVectors.load_word2vec_format('files/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def get_vector(word):\n",
    "    return model.get_vector(word)\n",
    "\n",
    "def sentence2vec(text):\n",
    "    \"\"\"\n",
    "    文字列を単語分割→ word2vecでベクトル化した平均を取る\n",
    "    英単語想定\n",
    "    \"\"\"\n",
    "    # 前処理\n",
    "    preprocessed_text = text.replace('\"','').replace('-','').replace(';','').replace(',','').replace('.','')\n",
    "    words = preprocessed_text.split(' ')\n",
    "    result_vec = np.zeros((1,300))\n",
    "    \n",
    "    n_error = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "#             result_vec += model.get_vector(word)\n",
    "            result_vec += get_vector(word)\n",
    "        except:\n",
    "            n_error += 1\n",
    "            \n",
    "    result_vec = result_vec/n_valid_words if (n_valid_words :=(len(words) - n_error)) != 0 else result_vec\n",
    "    return result_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y:(10684,)\n",
      "train_X:(10684, 300)\n",
      "CPU times: user 1.3 s, sys: 1.13 s, total: 2.43 s\n",
      "Wall time: 4.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "train_path = 'files/train.txt'\n",
    "train_y = []\n",
    "train_X = []\n",
    "\n",
    "with open(train_path) as f:\n",
    "    reader = csv.DictReader(f,fieldnames=['label','sentense'],delimiter='\\t')\n",
    "    for row in reader:\n",
    "        train_y.append(row['label'])\n",
    "        train_X.append(sentence2vec(row['sentense']))\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "train_X = np.vstack(train_X)\n",
    "print(f'train_y:{train_y.shape}\\ntrain_X:{train_X.shape}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_y:(1336,)\n",
      "valid_X:(1336, 300)\n",
      "CPU times: user 132 ms, sys: 46.1 ms, total: 178 ms\n",
      "Wall time: 527 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "valid_path = 'files/valid.txt'\n",
    "valid_y = []\n",
    "valid_X = []\n",
    "\n",
    "with open(valid_path) as f:\n",
    "    reader = csv.DictReader(f,fieldnames=['label','sentense'],delimiter='\\t')\n",
    "    for row in reader:\n",
    "        valid_y.append(row['label'])\n",
    "        valid_X.append(sentence2vec(row['sentense']))\n",
    "\n",
    "valid_y = np.array(valid_y)\n",
    "valid_X = np.vstack(valid_X)\n",
    "print(f'valid_y:{valid_y.shape}\\nvalid_X:{valid_X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_y:(1336,)\n",
      "test_X:(1336, 300)\n",
      "CPU times: user 116 ms, sys: 46.5 ms, total: 163 ms\n",
      "Wall time: 285 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "test_path = 'files/test.txt'\n",
    "test_y = []\n",
    "test_X = []\n",
    "\n",
    "with open(test_path) as f:\n",
    "    reader = csv.DictReader(f,fieldnames=['label','sentense'],delimiter='\\t')\n",
    "    for row in reader:\n",
    "        test_y.append(row['label'])\n",
    "        test_X.append(sentence2vec(row['sentense']))\n",
    "\n",
    "test_y = np.array(test_y)\n",
    "test_X = np.vstack(test_X)\n",
    "print(f'test_y:{test_y.shape}\\ntest_X:{test_X.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 71. 単層ニューラルネットワークによる予測\n",
    "問題70で保存した行列を読み込み，学習データについて以下の計算を実行せよ．\n",
    "\n",
    "$$ \\hat{\\boldsymbol{y}}_1 = {\\rm softmax}(\\boldsymbol{x}_1 W),$$\n",
    "$$ \\hat{Y} = {\\rm softmax}(X_{[1:4]} W)$$ \n",
    "\n",
    "ただし，softmax\n",
    "はソフトマックス関数，$X_{[1:4]} \\in \\mathbb{R}^{4 \\times d}$\n",
    "は特徴ベクトル$x_1,x_2,x_3,x_4$\n",
    "を縦に並べた行列である．\n",
    "\n",
    "行列$W \\in \\mathbb{R}^{d \\times L}$\n",
    "は単層ニューラルネットワークの重み行列で，ここではランダムな値で初期化すればよい（問題73以降で学習して求める）．なお，$\\hat{\\boldsymbol{y}}_1 \\in \\mathbb{R}^L$\n",
    "は未学習の行列$W$\n",
    "で事例$x_1$\n",
    "を分類したときに，各カテゴリに属する確率を表すベクトルである． 同様に，$ \\hat{Y} \\in \\mathbb{R}^{n \\times L}$\n",
    "は，学習データの事例$x_1,x_2,x_3,x_4$\n",
    "について，各カテゴリに属する確率を行列として表現している．\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 72. 損失と勾配の計算\n",
    "学習データの事例$x_1$\n",
    "と事例集合$x_1,x_2,x_3,x_4$\n",
    "に対して，クロスエントロピー損失と，行列$W$\n",
    "に対する勾配を計算せよ．なお，ある事例$x_i$\n",
    "に対して損失は次式で計算される．\n",
    "\n",
    "$$ l_i = - \\log [\\mbox{事例}x_i\\mbox{が}y_i\\mbox{に分類される確率}]$$\n",
    "\n",
    "ただし，事例集合に対するクロスエントロピー損失は，その集合に含まれる各事例の損失の平均とする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 73. 確率的勾配降下法による学習\n",
    "確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，行列$W$\n",
    "を学習せよ．なお，学習は適当な基準で終了させればよい（例えば「100エポックで終了」など）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 74. 正解率の計測\n",
    "問題73で求めた行列を用いて学習データおよび評価データの事例を分類したとき，その正解率をそれぞれ求めよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 75. 損失と正解率のプロット\n",
    "問題73のコードを改変し，各エポックのパラメータ更新が完了するたびに，訓練データでの損失，正解率，検証データでの損失，正解率をグラフにプロットし，学習の進捗状況を確認できるようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 76. チェックポイント\n",
    "問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 77. ミニバッチ化\n",
    "問題76のコードを改変し，B\n",
    "事例ごとに損失・勾配を計算し，行列$W$\n",
    "の値を更新せよ（ミニバッチ化）．B\n",
    "の値を1,2,4,8,…\n",
    "と変化させながら，1エポックの学習に要する時間を比較せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 78. GPU上での学習\n",
    "問題77のコードを改変し，GPU上で学習を実行せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 79. 多層ニューラルネットワーク\n",
    "問題78のコードを改変し，バイアス項の導入や多層化など，ニューラルネットワークの形状を変更しながら，高性能なカテゴリ分類器を構築せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('nlp-100-knocks-2020-UTXiV_Xd-py3.8': venv)",
   "language": "python",
   "name": "python38264bitnlp100knocks2020utxivxdpy38venv6f1bdc414e1c42079574c87f4d492959"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
